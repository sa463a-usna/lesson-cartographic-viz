{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SA463A &#x25aa; Data Wrangling and Visualization &#x25aa; Fall 2021 &#x25aa; Uhan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 11. Cartographic Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-_LXMfxPYNn"
   },
   "source": [
    "## In this lesson..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cartography** &mdash; the study and practice of map-making &mdash; has a rich history spanning centuries of discovery and design\n",
    "\n",
    "\n",
    "- **Cartographic visualization** leverages mapping techniques to convey data containing spatial information, such as locations, routes, or trajectories on the surface of the Earth\n",
    "\n",
    "\n",
    "- In this lesson, we'll learn about the basics of creating maps and visualizing spatial data with Altair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's start by importing our good friends, Pandas and Altair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's also enable the JSON data transformer and the JupyterLab renderer\n",
    "    - Don't forget to create a folder called `altair-data/`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.enable('json', prefix='altair-data/')\n",
    "alt.renderers.enable('jupyterlab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The GeoJSON format and geoshape marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Up to this point in the course, we have worked with datasets in CSV files that correspond to tabular data: \n",
    "    - Rows $\\leftrightarrow$ observations or records\n",
    "    - Columns $\\leftrightarrow$ variables or fields\n",
    "\n",
    "\n",
    "- **Geographic data**, such as *geographic regions* (e.g., countries, states) and *trajectories* (e.g., flight paths, subway lines) usually come in different formats\n",
    "\n",
    "\n",
    "- [GeoJSON](https://geojson.org/) is a format for encoding a variety of geographic data structures with JSON files\n",
    "\n",
    "\n",
    "- A **GeoJSON feature** represents a spatially bounded thing (like a country)\n",
    "\n",
    "\n",
    "- To illustrate, let's look at `data/maryland.geojson`, located in the same folder as this notebook, which contains a GeoJSON feature for the boundary of Maryland\n",
    "\n",
    "\n",
    "- As you can see, the `feature` contains:\n",
    "    - `properties`, like the `name` of the feature\n",
    "    - a `geometry` that consists of a list of `coordinates` given by `[longitude, latitude]` coordinates that define the state boundary\n",
    "\n",
    "\n",
    "- To visualize geographic data, Altair provides the `geoshape` mark type\n",
    "\n",
    "\n",
    "- For example, we can create a Chart object based on the GeoJSON feature specified `data/maryland.geojson`, and apply the `mark_geoshape()` method, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The TopoJSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [TopoJSON](https://github.com/topojson/topojson) is an extension of GeoJSON \n",
    "\n",
    "\n",
    "- A TopoJSON file can specify multiple GeoJSON features compactly by encoding the *topology* of geographic regions\n",
    "    - In particular, encoding borders shared between features only once\n",
    "\n",
    "\n",
    "- We can view TopoJSON data in a similar fashion to GeoJSON files, but with one additional step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To illustrate, we're going to use a dataset from the `vega_datasets` Python package\n",
    "    - This package provides access to a variety of [datasets hosted in the cloud by the Vega team](https://github.com/vega/vega-datasets)\n",
    "\n",
    "\n",
    "- Let's import the `data` object `vega_datasets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `data` object contains pointers to a number of datasets\n",
    "\n",
    "\n",
    "- For example, let's look at `data.world_110m`, which contains the boundaries of the world countries at a 110 meter resolution\n",
    "\n",
    "\n",
    "- We can get the URL of this dataset like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_url = data.world_110m.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's take a look at the contents of `world_url`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also read this file as a Python *dictionary* using `data.world_110m` as a *method*, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = data.world_110m()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's take a look at the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a result, we can, at a high level, quickly see the `'objects'` of `data.world_110m`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world['objects'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Roughly speaking, each `object` in a TopoJSON file corresponds to a collection of GeoJSON features\n",
    "\n",
    "\n",
    "- To use a TopoJSON file with a Chart object, we need to use a helper function, `alt.topo_feature()`, that extracts all the GeoJSON features from a particular TopoJSON `object`\n",
    "\n",
    "\n",
    "- For example, we can visualize the `land` object in `data.world_110m` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that `alt.topo_feature()` takes the URL as the first argument, not the dataset itself\n",
    "\n",
    "\n",
    "- Similarly, for the `countries` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geoshape mark properties and projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can customize the fill color, stroke color, and stroke widths using standard mark properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also change the default projection of the map using the `.project()` method, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The default projection `type` is `'mercator'`\n",
    "\n",
    "\n",
    "- There is a wide assortment of available projections\n",
    "    - [Vega documentation on the available cartographic projections](https://vega.github.io/vega/docs/projections/#types)\n",
    "\n",
    "\n",
    "- You can also use the `.project()` method to zoom into a particular part of the map with the following keyword arguments:\n",
    "    - `scale=...` specifies the magnification level as a number\n",
    "    - `translate=...` takes a 2-element list `[tx, ty]`, which specifies the pixel coordinates of the projection's center\n",
    "\n",
    "\n",
    "- You'll need to play around a bit with these keyword arguments to zoom into the part of the map you want\n",
    "\n",
    "\n",
    "- We can focus on Europe in the `'mercator'` projection like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point and symbol maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Many tabular datasets include geographic information such as:\n",
    "    - longitude and latitude coordinates\n",
    "    - references to geographic regions that can be mapped to coordinates (e.g. country names, postal codes)\n",
    "\n",
    "\n",
    "- We can combine this data with the *geometric* data in a GeoJSON or TopoJSON file to create maps with points or symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the same folder as this notebook, there is a CSV file `data/airports.csv` that contains a dataset of airports in the United States\n",
    "\n",
    "- Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df = pd.read_csv('data/airports.csv')\n",
    "airports_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The CSV file contains the following columns:\n",
    "\n",
    "| Column | Description |\n",
    "| :- | :- |\n",
    "| `iata` | Airport code |\n",
    "| `name` | Name of airport |\n",
    "| `city` | City of airport |\n",
    "| `state` | State of airport |\n",
    "| `latitude` | Latitude of airport |\n",
    "| `longitude` | Longitude of airport |\n",
    "| `routes` | Number of routes originating from airport |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's create a map that shows the location of each airport in this dataset\n",
    "\n",
    "\n",
    "- First, let's create a base layer containing a map of the US, including the state boundaries, using the `data.us_10m` dataset from `vega_datasets`\n",
    "\n",
    "\n",
    "- We start by getting the URL of this dataset, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_url = data.us_10m.url\n",
    "us_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's also read in the actual TopoJSON file as a dictionary, so we can peek at the structure and determine the objects available to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = data.us_10m()\n",
    "us['objects'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a `states` object! That seems promising &mdash; let's try it out\n",
    "\n",
    "\n",
    "- Let's configure our map as follows: \n",
    "    - fill color of `'lightgray'`\n",
    "    - stroke color of `'white'`\n",
    "    - stroke width of `1`\n",
    "    - `'albersUsa'` projection\n",
    "\n",
    "\n",
    "- As the name suggests, the `'albersUsa'` projection is well-suited for visualizations involving the US\n",
    "\n",
    "\n",
    "- So, we can create our base layer map like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we'll create a layer of points corresponding to the locations of the airports\n",
    "\n",
    "\n",
    "- We'll represent each observation/airport by a circle using `.mark_circle()`\n",
    "    - Let's make the points smaller than the default size, say `size=8`\n",
    "\n",
    "\n",
    "- To put the points in the correct places, we'll use the `Longitude` and `Latitude` encoding channels\n",
    "    - Note that we *don't* simply use the `alt.X()` and `alt.Y()` channels\n",
    "    - There is no guarantee that `longitude` → `x` and `latitude` → `y`!\n",
    "\n",
    "\n",
    "- Finally, let's add a tooltip that displays the corresponding airport code when the user mouses over each circle\n",
    "\n",
    "\n",
    "- So, something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, let's layer the two charts on top of each other, make our chart a little larger, and remove the rectangular border:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It would be nice to see the relative traffic of the airports &mdash; this way, we can identify major hubs\n",
    "\n",
    "\n",
    "- Let's modify the map we created above to visualize the number of routes with the `Size` encoding channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Food for thought.* What's the deal with the circles in the upper-left corner?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choropleth maps and the lookup transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **choropleth map** uses shaded or textured regions to visualize data values\n",
    "\n",
    "\n",
    "- Sized symbol maps, like the one we just created above, are often more accurate to read\n",
    "    - People tend to be better at estimating proportional differences between the area of circles than between color shades\n",
    "\n",
    "\n",
    "- Nevertheless, choropleth maps are useful when too many symbols become perceptually overwhelming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To illustrate, let's build a choropleth map of the unemployment rate per county, back in the recession year of 2008\n",
    "\n",
    "\n",
    "- We'll base our visualization on two datasets, both from `vega_datasets`: \n",
    "    1. a *tab-separated values* (TSV) file that contains unemployment statistics (`data.unemployment`)\n",
    "    2. a TopoJSON file that includes county boundary features (`data.usa_10m`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's store the URL of the unemployment data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unemp_url = data.unemployment.url\n",
    "unemp_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also peek at the structure of this dataset by downloading it in our browser\n",
    "\n",
    "\n",
    "- We see there are two columns:\n",
    "\n",
    "| Column | Description |\n",
    "| :- | :- |\n",
    "| `id` | [County FIPS code](https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county) |\n",
    "| `rate` | Unemployment rate |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Earlier, we stored \n",
    "    - the URL of `data.usa_10m` in the variable `us_url`\n",
    "    - the dataset as a dictionary in the variable `us`\n",
    "\n",
    "\n",
    "- Digging into the dictionary `us`, we saw that one of the objects in this TopoJSON dataset is `counties`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us['objects']['counties'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Digging a bit deeper into the `counties` object, we see  that it contains a list of `geometries`, each of which has an `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "us['objects']['counties']['geometries']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It turns out that `id` corresponds to the FIPS code of a county\n",
    "\n",
    "\n",
    "- So, we can use these county FIPS codes to match the geographic data in `data.usa_10m` with the unemployment data in `data.unemployment`\n",
    "\n",
    "\n",
    "- How? Let's start by making a map of the US counties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    alt.topo_feature(us_url, 'counties')\n",
    ").mark_geoshape(\n",
    "    stroke='lightgray',\n",
    "    strokeWidth=0.25\n",
    ").project(\n",
    "    type='albersUsa'\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").configure_view(\n",
    "    strokeWidth=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we can use a *lookup transform* to retrieve the values of `rate` in `unemp_url` for each value of `id` that matches between `unemp_url` and `us_url`\n",
    "\n",
    "\n",
    "- Then, we can encode the values of `rate` with `alt.Color()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The **lookup transform** extends the primary dataset given to a Chart object by looking up values from a secondary dataset\n",
    "\n",
    "\n",
    "- The `.transform_lookup()` method takes the following keyword arguments:\n",
    "    - `lookup=...` specifies the variable in the Chart's primary dataset that we'll use as a key to look up values in the secondary dataset\n",
    "    - `from_=...` takes an `alt.LookupData` object which specifies the secondary dataset\n",
    "\n",
    "\n",
    "- The `alt.LookupData()` function takes the following keyword arguments:\n",
    "    - `data=...` specifies the secondary dataset\n",
    "    - `key=...` specifies the variable in the secondary dataset to use as a key\n",
    "        - The values of this variable should match values of the variable specified in `lookup=...` in `.transform_lookup()`\n",
    "    - `fields=...` specifies a list of variables in the secondary dataset to extract\n",
    "\n",
    "\n",
    "- Let's put this all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `vega_datasets` package has a tabular dataset `data.zipcodes` of 5-digit zip codes in the United States. In particular, each row contains the `longitude` and `latitude` for the post office in each `zip_code`.\n",
    "\n",
    "Create a map of the United States, with state boundaries, that represents each post office location with a 1-pixel square mark. You should end up with something that looks like this:\n",
    "\n",
    "![](img/problem1.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any rhyme or reason to how the zip codes are allocated?\n",
    "\n",
    "Modify the map you created in Problem 1 by coloring the point for each zip code based on the *first digit* of the zip code.\n",
    "\n",
    "*Hint.* Create a new variable containing the first digit of each zip code. In the Vega expression syntax, you can get the first character of a string-valued `variable` with `datum.variable[0]`, similar to what you would do in Python.\n",
    "\n",
    "What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `vega_datasets` package has a tabular dataset `data.population_engineers_hurricanes`.\n",
    "\n",
    "1. Poke around the [vega-datasets website](https://github.com/vega/vega-datasets) and see if you can figure out what this dataset contains. See if you can find a description of the source of the data, as well as a preview of the data file itself.\n",
    "\n",
    "\n",
    "2. The `'states'` object of the TopoJSON dataset `data.us_10m` that we used earlier in this lesson contains a list of `geographies`, each of which has an associated `id` value. These values turn out to be the [state FIPS codes](https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code). Is there something similar in `data.population_engineers_hurricanes`? Do some Google sleuthing to verify your hunch.\n",
    "\n",
    "\n",
    "3. Use `data.us_10m` and `data.population_engineers_hurricanes` to create a chloropleth map of the United States that shows the population of each state with color. You should end up with something that looks like this:\n",
    "\n",
    "![](img/problem3.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes and sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These lesson notes are based on the [Visualization Curriculum](https://uwdata.github.io/visualization-curriculum/) by the University of Washington\n",
    "\n",
    "- [Altair example gallery of map visualizations](https://altair-viz.github.io/gallery/index.html#maps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
